# Sample Local install values file.

# Skaha web service deployment
deployment:
  hostname: example.org # Change this
  skaha:
    imagePullPolicy: IfNotPresent
    # Space delimited list of allowed Image Registry hosts.  These hosts should match the hosts in the User Session images.
    registryHosts: "images.canfar.net"

    # Root of shared storage
    skahaTld: "/cavern"
    
    # When set to 'true' this flag will enable GPU node scheduling.
    gpuEnabled: false 

    # The group name to verify users against for permission to use the Science Platform.
    usersGroup: "ivo://example.org/gms?example/users-group-name"

    adminsGroup: "ivo://example.org/gms?example/admin-group-name"

    headlessGroup: "ivo://example.org/gms?example/headless-group-name"

    headlessPriorityGroup: "ivo://example.org/gms?example/headless-priority-group-name"

    headlessPriorityClass: "uber-user-preempt-high"

    # Groups that can change the logging output level.
    # See log setting information at https://github.com/opencadc/core/tree/main/cadc-log#cadc-log
    loggingGroups:
      - "ivo://example.org/gms?/example/logging-group-1"
      - "ivo://example.org/gms?/example/logging-group-2"

    # The Resource ID of the Service that contains the Posix Mapping information
    posixMapperResourceID: "ivo://example.org/posix-mapper"

    # Session settings.
    sessions:
      expirySeconds: "345600" # Four days
      maxCount: "2"  # Users may have 2 interactive sessions at once
      minEphemeralStorage: "10Gi" # Initial request for ephemeral storage (scratch disk space)
      maxEphemeralStorage: "100Gi" # Max expansion for ephemeral storage (scratch disk space)
      extraVolumes:
      - name: cvmfs-mount
        volume:
          type: HOST_PATH     # HOST_PATH is for host path
          hostPath: "/cvmfs"  # Path on the Node to look for a source folder
          hostPathType: Directory
        volumeMount:
          mountPath: "/cvmfs"   # Path to mount on the User Sesssion Pod.
          readOnly: false
          mountPropagation: HostToContainer

    # Resources provided to the Skaha service.
    resources:
      requests:
        memory: "500M"
        cpu: "500m"
      limits:
        memory: "1500M"
        cpu: "1500m"

    # Optionally set the DEBUG port.
    # extraEnv:
    # - name: CATALINA_OPTS
    #   value: "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5555"
    # - name: JAVA_OPTS
    #   value: "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5555"

    # Uncomment to debug.  Requires options above as well as service port exposure below.
    # extraPorts:
    # - containerPort: 5555
    #   protocol: TCP

    # Optionally mount a custom CA certificate
    extraVolumeMounts:
    # - mountPath: "/config/cacerts"
    #   name: cacert-volume

    # If the base names have changed, then change them here, otherwise leave them.
    priorityClassName: uber-user-preempt-high
    serviceAccountName: skaha

    # Create the CA certificate volume to be mounted in extraVolumeMounts
    extraVolumes:
    # - name: cacert-volume
    #   secret:
    #     defaultMode: 420
    #     secretName: skaha-cacert-secret

secrets:
  # Uncomment to enable local or self-signed CA certificates for your domain to be trusted.
  # skaha-cacert-secret:
  #   ca.crt: <base64 encoded CA crt>

# Exposed extra ports.  Uncomment the java-debug port to expose and debug issues.
# service:
#   extraPorts:
  # - port: 5555
  #   protocol: TCP
  #   name: java-debug

# Set these labels appropriately to match your Persistent Volume labels.
# The storage.service.spec can be anything that supports ACLs, such as CephFS or Local.
# The CephFS Volume can be dynamically allocated here for the storage.service.spec:
# Example:
# storage:
#   service:
#     spec:
#       cephfs:
#         mons:
#           ...
# Default is a PersistentVolumeClaim to the Local Storage.
storage:
  service:
    spec:
      persistentVolumeClaim:
        claimName: skaha-pvc # Match this label up with whatever was installed in the base install, or the desired PVC, or create dynamically provisioned storage.
  sessions:
    claim:
      # storageClassName: ""
      labels:
        storage: local-storage  # Match this label up with whatever was installed in the base install, or the desired PVC

# Kueue setups
kueue:
  resourceFlavors:
  - name: skaha
    
  localQueues:
    skaha-workload-queue-interactive:
      namespace: skaha-workload
      clusterQueue: skaha-cluster-queue-interactive
    skaha-workload-queue-headless:
      namespace: skaha-workload
      clusterQueue: skaha-cluster-queue-headless

  clusterQueues:
    skaha-cluster-queue-interactive:
      cohort: "skaha-queue"
      resourceGroups:
      - coveredResources: ["cpu", "memory", "ephemeral-storage"]
        flavors:
        - name: skaha
          resources:
          - name: cpu
            nominalQuota: 6 # Change this according to the available resources
            borrowingLimit: 2 # Change this according to the resource requirements
          - name: memory
            nominalQuota: 6Gi # Change this according to the available resources
            borrowingLimit: 2Gi # Change this according to the available resources 
          - name: ephemeral-storage
            nominalQuota: 50Gi
    skaha-cluster-queue-headless:
      cohort: "skaha-queue"
      resourceGroups:
      - coveredResources: ["cpu", "memory", "ephemeral-storage"]
        flavors:
        - name: skaha
          resources:
          - name: cpu
            nominalQuota: 4 # Change this according to the available resources
            borrowingLimit: 0 # Change this according to the resource requirements
          - name: memory
            nominalQuota: 4Gi # Change this according to the available resources
            borrowingLimit: 0Gi # Change this according to the resource requirements
          - name: ephemeral-storage
            nominalQuota: 50Gi
